[
  {
    "objectID": "report.html",
    "href": "report.html",
    "title": "Ohio Urban Renewal Explorer - Technical Report",
    "section": "",
    "text": "A lot of dense urban neighborhoods in the United States were decimated by policies of Urban Renewal in the 1950s and 60s. These initiatives often involved constructing expanded roads, interstate highways, and other public works, but caused immense displacement of existing communities.\nProminent examples in cities such as Boston, New York City, and Pittsburgh have been widely studied and critiqued in works like Root Shock by Mindy Thompson-Fullilove and The Death and Life of Great American Cities by Jane Jacobs. In this report, I turn attention to a lesser-known case: the West End of Cincinnati, Ohio, exploring how similar policies impacted its urban fabric and communities.\nI focus on three primary data sources: aerial imagery from the Ohio Department of Transportation (ODOT), Sanborn Fire Insurance Maps from the 1920s and 1930s, and historical Census records. Using these sources and tools from Python, including OSMnx, I illustrate the loss of street connectivity, analyze socioeconomic trends, and highlight persistent barriers to revitalization in the West End."
  },
  {
    "objectID": "report.html#data-sources",
    "href": "report.html#data-sources",
    "title": "Ohio Urban Renewal Explorer - Technical Report",
    "section": "Data Sources",
    "text": "Data Sources\n\nODOT Historical Aerial Imagery\n\n\nSandborn Maps\nHistorical Sanborn Fire Insurance Maps served as a data source for this project, providing highly detailed overviews of the study area from the early 20th century. Accessing these documents through the Cincinnati Public Library digital collection and the Ohio Web Library, the maps were used to roughly reconstruct the historic street grid. The maps also provided insights on the neighborhood’s fabric by noting uses of certain buildings, such as churches and businesses (factories, gas stations, etc) that existed in the area prior to urban renewal.\n\n\nCensus Data & Longitudinal Tract Database"
  },
  {
    "objectID": "report.html#python-libraries-used",
    "href": "report.html#python-libraries-used",
    "title": "Ohio Urban Renewal Explorer - Technical Report",
    "section": "Python Libraries Used",
    "text": "Python Libraries Used"
  },
  {
    "objectID": "report.html#data-processing",
    "href": "report.html#data-processing",
    "title": "Ohio Urban Renewal Explorer - Technical Report",
    "section": "Data Processing",
    "text": "Data Processing"
  },
  {
    "objectID": "report.html#future-steps",
    "href": "report.html#future-steps",
    "title": "Ohio Urban Renewal Explorer - Technical Report",
    "section": "Future Steps",
    "text": "Future Steps"
  },
  {
    "objectID": "exploratory-analysis/historical-aerial-imagery.html",
    "href": "exploratory-analysis/historical-aerial-imagery.html",
    "title": "Historical Aerial Imagery Discovery",
    "section": "",
    "text": "Urban Renewal Explorer - Exploratory Analysis\n\n\n\nCode\nimport rasterio\nfrom rasterio.warp import calculate_default_transform, reproject, Resampling\nimport numpy as np\nimport pyproj\nfrom PIL import Image\nimport folium\nfrom folium import plugins\n\n\n\n\nCode\n# File Paths\nsrc_path = \"../data/historical-imagery/294-8-119.tif\"            # original ODOT TIFF (EPSG:4326)\nreproj_path = \"historical-aerial-imagery-output/historical_1950_3857.tif\"    # reprojection output\noverlay_png = \"historical-aerial-imagery-output/historical_overlay.png\"      # PNG for folium overlay\n\n# Reproject to Web Mercator (EPSG:3857) required by Folium\nwith rasterio.open(src_path) as src:\n    transform, width, height = calculate_default_transform(\n        src.crs, \"EPSG:3857\", src.width, src.height, *src.bounds\n    )\n\n    kwargs = src.meta.copy()\n    kwargs.update({\n        \"crs\": \"EPSG:3857\",\n        \"transform\": transform,\n        \"width\": width,\n        \"height\": height\n    })\n\n    with rasterio.open(reproj_path, \"w\", **kwargs) as dst:\n        reproject(\n            source=rasterio.band(src, 1),\n            destination=rasterio.band(dst, 1),\n            src_transform=src.transform,\n            src_crs=src.crs,\n            dst_transform=transform,\n            dst_crs=\"EPSG:3857\",\n            resampling=Resampling.bilinear,\n        )\n\n# READ RASTER + GET BOUNDS (EPSG:3857)\n# Then convert bounds → EPSG:4326 for Folium\nwith rasterio.open(reproj_path) as src:\n    img = src.read(1)\n    bounds_3857 = src.bounds\n\ntransformer = pyproj.Transformer.from_crs(\"EPSG:3857\", \"EPSG:4326\", always_xy=True)\nmin_lon, min_lat = transformer.transform(bounds_3857.left, bounds_3857.bottom)\nmax_lon, max_lat = transformer.transform(bounds_3857.right, bounds_3857.top)\n\n\n\n\nCode\nLAT_OFFSET = -0.0002  # Move image south/north\nLON_OFFSET = 0  # Move image west/east\n\n# SEPARATE WIDTH AND HEIGHT SCALING\nWIDTH_SCALE = 1.25   # Scale width (longitude) - values &gt; 1.0 stretch wider\nHEIGHT_SCALE = 1  # Scale height (latitude) - values &gt; 1.0 stretch taller\n\n# Calculate center point\ncenter_lat = (min_lat + max_lat) / 2\ncenter_lon = (min_lon + max_lon) / 2\n\n# Apply scaling around the center point with independent width/height\nlat_half_span = (max_lat - min_lat) / 2 * HEIGHT_SCALE\nlon_half_span = (max_lon - min_lon) / 2 * WIDTH_SCALE\n\nbounds_latlon = [\n    [center_lat - lat_half_span + LAT_OFFSET, center_lon - lon_half_span + LON_OFFSET],\n    [center_lat + lat_half_span + LAT_OFFSET, center_lon + lon_half_span + LON_OFFSET]\n]\n\n# CONVERT GRAYSCALE TIFF → RGB IMAGE FOR FOLIUM; Folium requires RGB/RGBA images\nnorm = ((img - img.min()) / (img.max() - img.min()) * 255).astype(\"uint8\")\nrgb = np.dstack([norm, norm, norm])\nImage.fromarray(rgb).save(overlay_png)\n\n\n\n\nCode\nwith rasterio.open(\"../data/historical-imagery/294-8-119.tif\") as src:\n    print(src.bounds)\n    print(src.transform)\n    print(src.crs)\n\nprint(f\"\\nAdjusted bounds with offset and scale:\")\nprint(f\"  SW: ({bounds_latlon[0][0]:.6f}, {bounds_latlon[0][1]:.6f})\")\nprint(f\"  NE: ({bounds_latlon[1][0]:.6f}, {bounds_latlon[1][1]:.6f})\")\n\n\n\nAdjusted bounds with offset and scale:\n  SW: (39.097413, -84.540747)\n  NE: (39.120322, -84.512108)\nBoundingBox(left=-84.53788339777749, bottom=39.0976117340363, right=-84.51497284736679, top=39.12052228444699)\n|-0.00, 0.00,-84.53|\n| 0.00, 0.00, 39.10|\n| 0.00, 0.00, 1.00|\nEPSG:4326\n\n\n\n\nCode\ncenter_lat = (min_lat + max_lat) / 2\ncenter_lon = (min_lon + max_lon) / 2\n\nm = folium.Map(\n    location=[center_lat, center_lon],\n    zoom_start=15,\n    tiles=\"openstreetmap\",\n)\n\n# Add satellite layer\nfolium.TileLayer(\n    tiles=\"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\",\n    attr=\"Esri\",\n    name=\"Satellite\",\n    overlay=False,\n    control=True\n).add_to(m)\n\nfolium.raster_layers.ImageOverlay(\n    name=\"1950 Aerial Imagery\",\n    image=overlay_png,\n    bounds=bounds_latlon,\n    opacity=0.6,\n).add_to(m)\n\nfolium.LayerControl().add_to(m)\n\n#  OPACITY SLIDER\nm.get_root().html.add_child(folium.Element(\"\"\"\n&lt;style&gt;\n#opacitySlider {\n  position: fixed;\n  top: 10px;\n  left: 50px;\n  z-index: 9999;\n  width: 200px;\n}\n&lt;/style&gt;\n\n&lt;input type=\"range\" min=\"0\" max=\"100\" value=\"60\" id=\"opacitySlider\"&gt;\n\n&lt;script&gt;\nvar slider = document.getElementById(\"opacitySlider\");\nslider.oninput = function() {\n    var opacity = this.value / 100;\n    document.querySelectorAll(\"img.leaflet-image-layer\").forEach(\n        function(img) { img.style.opacity = opacity; }\n    );\n}\n&lt;/script&gt;\n\"\"\"))\n\n\n&lt;branca.element.Element at 0x165165f90&gt;\n\n\n\n\nCode\n# Add drawing tools\ndraw = plugins.Draw(\n    export=True,\n    position='topleft',\n    draw_options={\n        'polyline': {'allowIntersection': False},\n        'polygon': False,\n        'circle': False,\n        'rectangle': False,\n        'marker': False,\n        'circlemarker': False,\n    }\n)\ndraw.add_to(m)\n\n# Simple, clean naming interface at the bottom\nm.get_root().html.add_child(folium.Element(\"\"\"\n&lt;style&gt;\n#streetControls {\n    position: fixed;\n    bottom: 30px;\n    left: 50%;\n    transform: translateX(-50%);\n    z-index: 9999;\n    background: white;\n    padding: 15px 20px;\n    border-radius: 8px;\n    box-shadow: 0 2px 10px rgba(0,0,0,0.3);\n    display: flex;\n    gap: 15px;\n    align-items: center;\n}\n#currentStreetName {\n    padding: 8px 12px;\n    border: 1px solid #ddd;\n    border-radius: 4px;\n    font-size: 14px;\n    width: 250px;\n}\n#downloadBtn {\n    padding: 8px 20px;\n    background: #2196F3;\n    color: white;\n    border: none;\n    border-radius: 4px;\n    cursor: pointer;\n    font-size: 14px;\n}\n#downloadBtn:hover {\n    background: #1976D2;\n}\n#streetCount {\n    font-size: 14px;\n    color: #666;\n}\n&lt;/style&gt;\n\n&lt;div id=\"streetControls\"&gt;\n    &lt;input type=\"text\" id=\"currentStreetName\" placeholder=\"Enter street name, then draw\"&gt;\n    &lt;span id=\"streetCount\"&gt;Streets: 0&lt;/span&gt;\n    &lt;button id=\"downloadBtn\" onclick=\"downloadStreets()\"&gt;Download&lt;/button&gt;\n&lt;/div&gt;\n\n&lt;script&gt;\nvar drawnStreets = [];\n\nvar mapElement = document.querySelector('.folium-map');\nvar map = mapElement ? (mapElement._leaflet_map || window[Object.keys(window).find(k =&gt; window[k]?._container === mapElement)]) : null;\n\nif (!map) {\n    setTimeout(function() {\n        var maps = Object.keys(window).filter(k =&gt; window[k] instanceof L.Map);\n        if (maps.length &gt; 0) {\n            map = window[maps[0]];\n            setupDrawListener();\n        }\n    }, 1000);\n} else {\n    setupDrawListener();\n}\n\nfunction setupDrawListener() {\n    map.on('draw:created', function (e) {\n        var layer = e.layer;\n        var streetName = document.getElementById('currentStreetName').value || 'Unnamed Street ' + (drawnStreets.length + 1);\n\n        var coords = layer.getLatLngs().map(function(latlng) {\n            return [latlng.lng, latlng.lat];\n        });\n\n        var street = {\n            type: 'Feature',\n            properties: {\n                name: streetName,\n                year: 1950,\n                id: drawnStreets.length\n            },\n            geometry: {\n                type: 'LineString',\n                coordinates: coords\n            }\n        };\n\n        drawnStreets.push(street);\n\n        document.getElementById('streetCount').textContent = 'Streets: ' + drawnStreets.length;\n        document.getElementById('currentStreetName').value = '';\n\n        layer.bindPopup('&lt;b&gt;' + streetName + '&lt;/b&gt;').openPopup();\n    });\n}\n\nfunction downloadStreets() {\n    if (drawnStreets.length === 0) {\n        alert('No streets to download!');\n        return;\n    }\n\n    var geojson = {\n        type: 'FeatureCollection',\n        features: drawnStreets\n    };\n\n    var dataStr = \"data:text/json;charset=utf-8,\" + encodeURIComponent(JSON.stringify(geojson, null, 2));\n    var downloadAnchor = document.createElement('a');\n    downloadAnchor.setAttribute(\"href\", dataStr);\n    downloadAnchor.setAttribute(\"download\", \"cincinnati_streets_1950s.geojson\");\n    document.body.appendChild(downloadAnchor);\n    downloadAnchor.click();\n    downloadAnchor.remove();\n\n    alert('Downloaded ' + drawnStreets.length + ' streets!');\n}\n&lt;/script&gt;\n\"\"\"))\n\nm.save('historical-aerial-imagery-output/map_with_named_drawing.html')\n\n\n\n\nCode\nm\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "exploratory-analysis/census-data.html",
    "href": "exploratory-analysis/census-data.html",
    "title": "Census Data Discovery",
    "section": "",
    "text": "Urban Renewal Explorer - Exploratory Analysis\n\n\nBackground\nA main component of my final project is analyzing socioeconomic change in neighborhoods that experienced urban renewal over several decades. The challenge is that Census tract boundaries change regularly which makes direct comparison over time more complicated than simply lining up decennial Census data.\nBased on online research, and a mention in MUSA 5080, the Longitudinal Tract Data Base (LTDB) seemed like a promising contender to address this challenge. This database provides estimates within 2010 tract boundaries for tract-level census data, going back as early as 1970. Of course, this excludes some of the immediate impacts of Urban Renewal in the 50s and 60s, and makes it harder to interpret 2020 data (outisde of race). This can be explored in future improvements to this project.\nSince usage of this database was not covered in class, I conduct some code exploration below.\n\nFirst, I load in Cincinnati City boundaries, including neighborhoods.\nThen I bring in regular Census API data and produce some visualizations.\nFinally, I explore the LTDB data.\n\n\n\nCode\n# Setup\nimport geopandas as gpd\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cenpy\nimport pygris\nimport folium\nimport branca.colormap as cm\n\n\n\n\nCincinnati Neighborhood Boundaries & Census Tract Exploration\nIn the next few code blocks, I load in 2020 Cincinnati Statistic Neighborhood Approximation (SNA) Boundaries, retrieved from [Cincinnati Data] (https://data.cincinnati-oh.gov/dataset/Cincinnati-Statistical-Neighborhood-Approximations/i9zh-juvu/about_data). I also grab census tracts using pygris for Hamilton County, plot that, and then filter down to census tracts that include any part of Cincinnati.\n\n\nCode\n# Load Cincinnati neighborhood boundaries\ncinci_sna_gdf = gpd.read_file(\"../data/boundaries/Cinci_SNA_2020.geojson\")\n\nfig, ax = plt.subplots(figsize=(10, 10))\ncinci_sna_gdf.plot(ax=ax, edgecolor=\"black\", facecolor=\"lightgray\")\n\nax.set_title(\"Cincinnati Neighborhood Boundaries (SNA 2020)\", fontsize=14)\nax.axis(\"off\")\n\noutput_filename = \"census-data-output/cinci_sna_boundaries.png\"\nplt.savefig(\n    output_filename,\n    dpi=200,\n    bbox_inches='tight',\n    facecolor='white',\n    transparent=True\n)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# FIPS Code for Ohio = 39. Pulling all tracts for 2021\nohio_tracts = pygris.tracts(state=\"39\", year=2021)\n\n# FIPS Code for Hamilton County = 061\nhamilton_tracts = ohio_tracts[ohio_tracts[\"COUNTYFP\"] == \"061\"].copy()\n\nfig, ax = plt.subplots(1, 1, figsize=(10, 10))\nhamilton_tracts.plot(\n    edgecolor=\"black\",\n    facecolor=\"none\",\n    linewidth=0.8,\n    ax=ax\n)\nax.set_title(\"Hamilton County Census Tracts (2021)\")\nax.axis(\"off\")\n\noutput_filename = \"census-data-output/hamilton_county_tracts.png\"\nplt.savefig(\n    output_filename,\n    dpi=200,\n    bbox_inches='tight',\n    facecolor='white',\n    transparent=True\n)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Ensure CRS Match\nhamilton_tracts = hamilton_tracts.to_crs(cinci_sna_gdf.crs)\n\n#inner join to keep only tracts that intersect with the neighborhood boundaries\ncinci_tracts = gpd.sjoin(\n    hamilton_tracts,\n    cinci_sna_gdf,\n    how=\"inner\",\n    predicate=\"intersects\"\n)\n\n# Remove any duplicate tracts\ncinci_tracts = cinci_tracts.drop_duplicates(subset=['GEOID'])\n\n# Plot neighborhood as gray overlay\nfig, ax = plt.subplots(figsize=(10, 10))\ncinci_sna_gdf.plot(ax=ax, color=\"lightgray\", edgecolor=\"white\", alpha=0.5)\n\n# Plot tracts\ncinci_tracts.plot(\n    ax=ax,\n    edgecolor=\"blue\",\n    facecolor=\"none\",\n    linewidth=1,\n    label=\"Filtered Tracts\"\n)\nax.set_title(\"Census Tracts (Blue Outlines) Including Cincinnati City Boundaries (Light Gray)\", fontsize=14)\nax.axis(\"off\")\n\noutput_filename = \"census-data-output/census_tracts_cinci_sna.png\"\nplt.savefig(\n    output_filename,\n    dpi=200,\n    bbox_inches='tight',\n    facecolor='white',\n    transparent=True\n)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n2021 Census Data Exploration\nIn the following code blocks, I grab data from the 2021 ACS 5-year estimate. I also map that against the Cincinnati Census Tracts.\n\n\nCode\n# ACS 5-year dataset (2021)\nacs = cenpy.remote.APIConnection(\"ACSDT5Y2021\")\n\n# B19013_001E = Median Household Income\nvariables = [\"B19013_001E\"]\n\nincome_data = acs.query(\n    cols=variables,\n    geo_unit=\"tract\",\n    geo_filter={\"state\": \"39\", \"county\": \"061\"}\n)\nincome_data[\"GEOID\"] = (\n        income_data[\"state\"].astype(str) +\n        income_data[\"county\"].astype(str) +\n        income_data[\"tract\"].astype(str).str.zfill(6)\n)\nincome_data = income_data.rename(columns={\"B19013_001E\": \"Median_HH_Income\"})\n\nprint(income_data.head())\n\n\n  Median_HH_Income state county   tract        GEOID\n0            18049    39    061  000200  39061000200\n1            94100    39    061  000700  39061000700\n2            78421    39    061  000900  39061000900\n3            79007    39    061  001000  39061001000\n4            66680    39    061  001100  39061001100\n\n\n\n\nCode\n# Here, I merge the income data with Cinci Tracts\ncinci_tracts[\"GEOID\"] = cinci_tracts[\"GEOID\"].astype(str)\n\ncinci_income_tracts = cinci_tracts.merge(\n    income_data[[\"GEOID\", \"Median_HH_Income\"]],\n    on=\"GEOID\",\n    how=\"left\"\n)\n\n# Convert income to numeric for mapping\ncinci_income_tracts[\"Median_HH_Income\"] = pd.to_numeric(\n    cinci_income_tracts[\"Median_HH_Income\"], errors='coerce'\n)\n\n\n\n\nCode\n# Replace the specific Census null flag with actual NaN\ncinci_income_tracts.loc[cinci_income_tracts[\"Median_HH_Income\"] &lt; 0, \"Median_HH_Income\"] = None\n\nfig, ax = plt.subplots(figsize=(14, 10))\nplot = cinci_income_tracts.plot(\n    column=\"Median_HH_Income\",\n    cmap=\"viridis\",\n    legend=True,\n    edgecolor=\"black\",\n    linewidth=0.3,\n    ax=ax,\n    missing_kwds={\"color\": \"lightgrey\", \"label\": \"No Data\"},\n    legend_kwds={\n        \"label\": \"Median Household Income ($)\",\n        \"orientation\": \"horizontal\",\n        \"shrink\": 0.5,\n        \"pad\": 0.01,\n        \"fmt\": \"${x:,.0f}\"\n    }\n)\nax.set_title(\"Cincinnati Household Median Income by Census Tract (2021 5-year ACS)\", fontsize=16, pad=20)\nax.axis(\"off\")\n\noutput_filename = \"census-data-output/cinci_mhh_inc.png\"\nplt.savefig(\n    output_filename,\n    dpi=200,\n    bbox_inches='tight',\n    facecolor='white',\n    transparent=True\n)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nTarget Neighborhoods\nMy report is focused on urban renewal that impacted the urban core of Cincinnati, specifically the West End and Queensgate. Neighborhoods nearby, primarily Over-the-Rhine, Downtown, and Pendleton were also impacted by Urban Renewal but kept their urban fabric (where as the West End and Queensgate were almost entirely demolished in an attempt to become an industrial/logistics zone).\n\n\nCode\ntarget_neighborhoods = [\n    \"West End\",\n    \"Lower Price Hill_Queensgate\",\n    \"Pendleton\",\n    \"Downtown\",\n    \"Over-the-Rhine\"\n]\nfocus_areas = cinci_sna_gdf[cinci_sna_gdf['SNA_NAME'].isin(target_neighborhoods)]\n\n# Get the bounding box: [minx, miny, maxx, maxy]\nminx, miny, maxx, maxy = focus_areas.total_bounds\n\n# Add a small buffer (approx 5%) so the edges aren't touching the frame\nbuffer = 0.005\nxlim = ([minx - buffer, maxx + buffer])\nylim = ([miny - buffer, maxy + buffer])\n\n\nfig, ax = plt.subplots(figsize=(12, 10))\ncinci_income_tracts.plot(\n    column=\"Median_HH_Income\",\n    cmap=\"viridis\",\n    edgecolor=\"white\",\n    linewidth=0.5,\n    ax=ax,\n    legend=True,\n    legend_kwds={'label': \"Median HH Income ($)\", \"orientation\": \"horizontal\"},\n    missing_kwds={\"color\": \"lightgrey\"}\n)\n\nfocus_areas.plot(\n    ax=ax,\n    facecolor=\"none\",\n    edgecolor=\"red\",\n    linewidth=2.5,\n    alpha=0.9\n)\n\n# Add neighborhood names\nfor x, y, label in zip(focus_areas.geometry.centroid.x,\n                       focus_areas.geometry.centroid.y,\n                       focus_areas['SNA_NAME']):\n    ax.text(x, y, label, fontsize=10, fontweight='bold',\n            ha='center', va='center',\n            bbox=dict(facecolor='white', alpha=0.7, edgecolor='none', pad=2))\n\nax.set_xlim(xlim)\nax.set_ylim(ylim)\nax.set_title(\"Median Household Income by Census Tract in Target Neighborhoods \\n(2021 5-year ACS)\", fontsize=15)\nax.axis(\"off\")\n\noutput_filename = \"census-data-output/cinci_target_neigh_inc.png\"\nplt.savefig(\n    output_filename,\n    dpi=200,\n    bbox_inches='tight',\n    facecolor='white',\n    transparent=True\n)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nLongitudinal Tract Database (LTDB)\nFinally, I wanted to view Median Household Income across the Hamilton County Area, with an emphasis on my focus neighborhoods across time (from 1970 to 2015). For this, I used the aforementioned LTDB which standardizes census data to 2010 tract boundaries. This required a fair amount of data processing, as their website is a bit out of data and they do not have an API. Instead, you must download the CSVs with estimates, and use their codebook to understand column headers. These are not standardizes across files!\n\n\nCode\n# --- Step 1: Load Hamilton County tracts (2010) ---\nohio_tracts = pygris.tracts(state='39', year=2010)  # Ohio\n# Filter for Hamilton County FIPS = '061'\nhamilton_tracts_2010 = ohio_tracts[ohio_tracts['COUNTYFP10'] == '061']\n\n# --- Step 2: Load LTDB CSVs into dictionary ---\nfolder = \"../data/ltdb_std_all_sample/\"\n\ndfs = {\n    '1970': pd.read_csv(f\"{folder}ltdb_std_1970_sample.csv\", encoding='latin1'),\n    '1980': pd.read_csv(f\"{folder}ltdb_std_1980_sample.csv\", encoding='latin1'),\n    '1990': pd.read_csv(f\"{folder}ltdb_std_1990_sample.csv\", encoding='latin1'),\n    '2008': pd.read_csv(f\"{folder}LTDB_std_200812_Sample.csv\", encoding='latin1'),\n    '2015': pd.read_csv(f\"{folder}LTDB_std_201519_Sample.csv\", encoding='latin1'),\n}\n\n# --- Step 3: Define county/state columns ---\ncounty_cols = {\n    '1970': ('county', 'state'),\n    '1980': ('county', 'state'),\n    '1990': ('county', 'state'),\n    '2008': ('countya', 'statea'),\n    '2015': ('countya', 'statea')\n}\n\ncounty_vals = {\n    '1970': ('Hamilton County', 'OH'),\n    '1980': ('Hamilton County', 'OH'),\n    '1990': ('Hamilton County', 'OH'),\n    '2008': (' Hamilton County', ' Ohio'),\n    '2015': (' Hamilton County', ' Ohio')\n}\n\n# --- Step 4: HH income columns ---\nhhinc_cols = {\n    '1970': 'HINC70',\n    '1980': 'hinc80',\n    '1990': 'HINC90',\n    '2008': 'hinc12',\n    '2015': 'hinc19'\n}\n\n# --- Step 5: Tract column per year ---\ntractid_cols = {\n    '1970': 'TRTID10',\n    '1980': 'trtid10',\n    '1990': 'TRTID10',\n    '2008': 'tractid',\n    '2015': 'tractid'\n}\n\n# --- Step 6: Filter for Hamilton County ---\nprint(\"=== Filtering for Hamilton County ===\")\nfor year, df in dfs.items():\n    county_col, state_col = county_cols[year]\n    county_val, state_val = county_vals[year]\n\n    # Filter for Hamilton County\n    dfs[year] = df[(df[county_col] == county_val) & (df[state_col] == state_val)].copy()\n    print(f\"{year}: {len(dfs[year])} Hamilton County tracts found\")\n\n\n=== Filtering for Hamilton County ===\n1970: 222 Hamilton County tracts found\n1980: 222 Hamilton County tracts found\n1990: 222 Hamilton County tracts found\n2008: 222 Hamilton County tracts found\n2015: 222 Hamilton County tracts found\n\n\n\n\nCode\n# --- Step 7: Merge with GeoDataFrame using tract IDs ---\nprint(\"\\n=== Merging with Census Geography ===\")\nmerged_dfs = {}\n\nfor year, df in dfs.items():\n    if len(df) == 0:\n        print(f\"{year}: No data after county filter, skipping...\")\n        continue\n\n    tractid_col = tractid_cols[year]\n\n    # Extract last 6 digits from tract ID (format is SSCCCTTTTTT where TT is tract)\n    # For Hamilton County, Ohio (39061), we want the last 6 digits\n    df['tract_6digit'] = df[tractid_col].astype(str).str[-6:]\n\n    # Check for matches\n    matches = df['tract_6digit'].isin(hamilton_tracts_2010['TRACTCE10']).sum()\n    print(f\"{year}: {matches}/{len(df)} tracts match census geography\")\n\n    # Perform merge\n    merged = hamilton_tracts_2010.merge(\n        df[[tractid_col, 'tract_6digit', hhinc_cols[year]]],\n        left_on='TRACTCE10',\n        right_on='tract_6digit',\n        how='left'\n    )\n\n    # Keep geometry and HH income\n    merged = merged[['geometry', hhinc_cols[year]]].copy()\n    merged.rename(columns={hhinc_cols[year]: 'income'}, inplace=True)\n    merged_dfs[year] = merged\n\n    print(f\"{year}: Final result - {len(merged)} tracts, {merged['income'].notna().sum()} with income data\")\n\n\n\n=== Merging with Census Geography ===\n1970: 222/222 tracts match census geography\n1970: Final result - 222 tracts, 222 with income data\n1980: 222/222 tracts match census geography\n1980: Final result - 222 tracts, 217 with income data\n1990: 222/222 tracts match census geography\n1990: Final result - 222 tracts, 222 with income data\n2008: 222/222 tracts match census geography\n2008: Final result - 222 tracts, 222 with income data\n2015: 222/222 tracts match census geography\n2015: Final result - 222 tracts, 222 with income data\n\n\n\n\nCode\nimport folium\nimport branca.colormap as cm\n\nm = folium.Map(location=[39.1031, -84.5120], zoom_start=11, tiles=None)\n\ntile_url = 'https://{s}.basemaps.cartocdn.com/light_all/{z}/{x}/{y}{r}.png'\ntile_attribution = '&copy; OpenStreetMap &copy; CARTO'\ncolormap = cm.linear.viridis.scale(0, 150000)\ncolormap.caption = 'Household Income ($)'\n\nfor year in sorted(merged_dfs.keys()):\n    gdf = merged_dfs[year]\n\n    if gdf.crs != 'EPSG:4326':\n        gdf = gdf.to_crs(epsg=4326)\n\n    year_group = folium.FeatureGroup(name=f\"Income {year}\", overlay=False)\n    folium.TileLayer(tile_url, attr=tile_attribution).add_to(year_group)\n\n    valid_data = gdf.dropna(subset=['income'])\n    folium.GeoJson(\n        valid_data,\n        style_function=lambda feature: {\n            'fillColor': colormap(feature['properties']['income']),\n            'color': 'black',\n            'weight': 0.5,\n            'fillOpacity': 0.7,\n        },\n        tooltip=folium.GeoJsonTooltip(\n            fields=['income'],\n            aliases=['Income: $'],\n            localize=True\n        )\n    ).add_to(year_group)\n\n    year_group.add_to(m)\n\n# Add Focus Areas (Checkbox Overlay)\nif focus_areas.crs != 'EPSG:4326':\n    focus_areas = focus_areas.to_crs(epsg=4326)\n\nfocus_group = folium.FeatureGroup(name=\"Target Neighborhoods\", show=True)\nfolium.GeoJson(\n    focus_areas,\n    style_function=lambda feature: {\n        'fillColor': 'none',\n        'color': '#e31a1c',\n        'weight': 4,\n        'dashArray': '5, 5',\n    },\n    tooltip=folium.GeoJsonTooltip(\n        fields=['SNA_NAME'],\n        aliases=['Area Name:']\n    )\n).add_to(focus_group)\nfocus_group.add_to(m)\n\ncolormap.add_to(m)\nfolium.LayerControl(collapsed=False).add_to(m)\n\nbounds = focus_areas.total_bounds\nfolium_bounds = [[bounds[1], bounds[0]], [bounds[3], bounds[2]]]\nm.fit_bounds(folium_bounds)\n\n# Save and display\nm.save('census-data-output/hamilton_county_ltdb.html')\nm\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "exploratory-analysis/osmnx-exploration.html",
    "href": "exploratory-analysis/osmnx-exploration.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All Code\n\n\n\n\n\n\n\nCode\n# full_fixed_osmnx_script.py\nimport osmnx as ox\nimport networkx as nx\nimport geopandas as gpd\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom shapely.geometry import Point, LineString\nimport numpy as np\nimport json\n\nox.settings.use_cache = True\nox.settings.log_console = False\n\n# Using the aerial image\n# SW: (39.097413, -84.540747), NE: (39.120322, -84.512108)\nnorth = 39.120322\nsouth = 39.097413\neast = -84.512108\nwest = -84.540747\n\nprint(\"\\nDownloading current street network from OpenStreetMap...\")\nG = ox.graph_from_bbox(north, south, east, west, network_type=\"drive\")\nprint(f\"Network has {len(G.nodes)} nodes and {len(G.edges)} edges\")\n\nnodes_gdf, edges_gdf = ox.graph_to_gdfs(G)\n\n# edges_gdf['length'] is in meters in OSMnx\nif \"length\" in edges_gdf.columns:\n    total_length_km = edges_gdf[\"length\"].sum() / 1000.0\nelse:\n    total_length_km = edges_gdf.geometry.length.sum() / 1000.0\n\nprint(f\"\\nTotal street length: {total_length_km:.2f} km\")\n\n\ndef safe_buffer_zero(geom):\n    try:\n        if geom is None:\n            return None\n        fixed = geom.buffer(0)\n        if fixed.is_empty:\n            return geom\n        return fixed\n    except Exception:\n        return geom\n\n\ndef flatten_value_for_geojson(v):\n    if pd.isna(v):\n        return None\n    if isinstance(v, (list, tuple, set)):\n        return \", \".join(map(lambda x: str(x) if x is not None else \"\", v))\n    if isinstance(v, dict):\n        try:\n            return json.dumps(v, ensure_ascii=False)\n        except Exception:\n            return str(v)\n    if isinstance(v, (np.integer, np.floating, np.bool_)):\n        return v.item()\n    return v\n\nprint(\"\\n=== Basic Network Statistics ===\")\ntry:\n    stats = ox.basic_stats(G)\n    for key, value in stats.items():\n        if isinstance(value, (int, float)):\n            print(f\"{key}: {value:.4f}\" if isinstance(value, float) else f\"{key}: {value}\")\n        else:\n            print(f\"{key}: {type(value).__name__}\")\nexcept Exception as e:\n    print(\"Warning: ox.basic_stats failed:\", e)\n\nprint(\"\\n=== Calculating Centrality Metrics ===\")\nprint(\"Note: for MultiDiGraph we aggregate to a simple undirected graph for centrality calculations.\")\n\n# Create a simplified undirected Graph for centrality metrics.\n# We aggregate parallel edges by taking the minimum 'length' (if present).\nGu = nx.Graph()\nfor u, v, data in G.edges(data=True):\n    length = data.get(\"length\", None)\n    if length is None:\n        # fallback to 1 if no length attribute; closeness/betweenness require positive distance\n        length = 1.0\n    # networkx Graph allows only one edge per (u, v) tuple; we keep smallest length\n    if Gu.has_edge(u, v):\n        # keep the smallest length\n        if length &lt; Gu[u][v].get(\"length\", np.inf):\n            Gu[u][v][\"length\"] = length\n    else:\n        Gu.add_edge(u, v, length=length)\n\n# Betweenness centrality - on the undirected simplified graph\nprint(\"Calculating betweenness centrality (this can be slow for bigger graphs)...\")\ntry:\n    betweenness = nx.betweenness_centrality(Gu, weight=\"length\", normalized=True)\nexcept Exception as e:\n    print(\"Betweenness centrality failed or is too slow; falling back to unweighted version. Error:\", e)\n    betweenness = nx.betweenness_centrality(Gu, normalized=True)\n\n# Closeness centrality - uses 'length' as distance\nprint(\"Calculating closeness centrality...\")\ntry:\n    closeness = nx.closeness_centrality(Gu, distance=\"length\")\nexcept Exception as e:\n    print(\"Closeness centrality fell back to unweighted version. Error:\", e)\n    closeness = nx.closeness_centrality(Gu)\n\n# Degree centrality - use original directed graph's degree (or undirected version)\ndegree_centrality = nx.degree_centrality(Gu)\n\n# Map centrality values back to nodes_gdf (index is node id)\nnodes_gdf = nodes_gdf.copy()\nnodes_gdf[\"betweenness\"] = nodes_gdf.index.map(lambda nid: betweenness.get(nid, 0.0))\nnodes_gdf[\"closeness\"] = nodes_gdf.index.map(lambda nid: closeness.get(nid, 0.0))\nnodes_gdf[\"degree_centrality\"] = nodes_gdf.index.map(lambda nid: degree_centrality.get(nid, 0.0))\n\nprint(\"Centrality calculations complete!\")\n\n# ============================================================================\n# 5. ANALYZE STREET CONNECTIVITY\n# ============================================================================\n\ndead_ends = [node for node, degree in G.degree() if degree == 1]\nprint(f\"\\nNumber of dead ends: {len(dead_ends)}\")\n\nintersections = [node for node, degree in G.degree() if degree &gt;= 3]\nprint(f\"Number of intersections: {len(intersections)}\")\n\navg_degree = sum(dict(G.degree()).values()) / max(1, len(G.nodes()))\nprint(f\"Average node degree: {avg_degree:.2f}\")\n\n# ============================================================================\n# 6. VISUALIZATIONS\n# ============================================================================\n\n# Plot 1: Basic network (ox.plot_graph returns matplotlib figure, ax)\nfig, ax = ox.plot_graph(\n    G,\n    node_size=0,\n    edge_linewidth=0.5,\n    bgcolor=\"white\",\n    edge_color=\"black\",\n    figsize=(12, 12),\n    show=False,\n    close=False,\n)\nplt.title(\"Current Street Network\", fontsize=16)\nplt.tight_layout()\nplt.show()\n\n# Plot 2: Betweenness centrality (nodes)\nfig, ax = plt.subplots(figsize=(12, 12))\nnodes_gdf.plot(\n    column=\"betweenness\",\n    ax=ax,\n    cmap=\"Reds\",\n    markersize=20,\n    legend=True,\n    legend_kwds={\"label\": \"Betweenness Centrality\"},\n)\nedges_gdf.plot(ax=ax, color=\"gray\", linewidth=0.5, alpha=0.5)\nplt.title(\"Node Betweenness Centrality\\n(Red = Important Connectors)\", fontsize=14)\nplt.axis(\"off\")\nplt.tight_layout()\nplt.show()\n\n# Plot 3: Closeness centrality (nodes)\nfig, ax = plt.subplots(figsize=(12, 12))\nnodes_gdf.plot(\n    column=\"closeness\",\n    ax=ax,\n    cmap=\"Blues\",\n    markersize=20,\n    legend=True,\n    legend_kwds={\"label\": \"Closeness Centrality\"},\n)\nedges_gdf.plot(ax=ax, color=\"gray\", linewidth=0.5, alpha=0.5)\nplt.title(\"Node Closeness Centrality\\n(Blue = Most Accessible)\", fontsize=14)\nplt.axis(\"off\")\nplt.tight_layout()\nplt.show()\n\n# ============================================================================\n# 7. CLEAN GEOMETRIES + FLATTEN ATTRIBUTES BEFORE EXPORT\n# ============================================================================\n\nprint(\"\\nCleaning geometries and attributes for export...\")\n\n# 1) Remove NaN geometries\nedges_gdf = edges_gdf[edges_gdf.geometry.notna()].copy()\nnodes_gdf = nodes_gdf[nodes_gdf.geometry.notna()].copy()\n\n# 2) Attempt to fix invalid geometries using buffer(0)\nedges_gdf[\"geometry\"] = edges_gdf[\"geometry\"].apply(safe_buffer_zero)\nnodes_gdf[\"geometry\"] = nodes_gdf[\"geometry\"].apply(safe_buffer_zero)\n\n# Optionally drop any empty geometries that couldn't be fixed\nedges_gdf = edges_gdf[~edges_gdf.geometry.is_empty].copy()\nnodes_gdf = nodes_gdf[~nodes_gdf.geometry.is_empty].copy()\n\n# 3) Flatten list/dict-like columns to strings (GeoJSON can't store Python lists)\nfor gdf in (nodes_gdf, edges_gdf):\n    for col in gdf.columns:\n        if col == \"geometry\":\n            continue\n        # apply flattening with a safe conversion\n        try:\n            gdf[col] = gdf[col].apply(flatten_value_for_geojson)\n        except Exception:\n            # fallback: convert whole column to string\n            gdf[col] = gdf[col].astype(str).where(~gdf[col].isna(), None)\n\nprint(\"Geometry + attribute cleaning complete!\")\n\n# ============================================================================\n# 8. EXPORT FOR FURTHER ANALYSIS\n# ============================================================================\n\n# Save to GeoJSON files\n# If you prefer shapefile, note shapefile has stricter type limits and field name length limits.\nnodes_gdf.to_file(\"current_network_nodes.geojson\", driver=\"GeoJSON\")\nedges_gdf.to_file(\"current_network_edges.geojson\", driver=\"GeoJSON\")\n\nprint(\"\\n=== Files saved successfully ===\")\nprint(\"- current_network_nodes.geojson\")\nprint(\"- current_network_edges.geojson\")\n\n\nStudy area bounds:\n  North: 39.120322, South: 39.097413\n  East: -84.512108, West: -84.540747\n  Area: ~2.54 km × 2.47 km\n\nDownloading current street network from OpenStreetMap...\nThis may take a minute...\n\n\nNetwork has 618 nodes and 1369 edges\n\nNodes columns: ['y', 'x', 'ref', 'highway', 'street_count', 'geometry']\nEdges columns: ['osmid', 'oneway', 'lanes', 'highway', 'reversed', 'length', 'geometry', 'ref', 'name', 'maxspeed', 'bridge', 'access', 'area', 'tunnel', 'junction']\n\nTotal street length: 144.03 km\n\n=== Basic Network Statistics ===\nn: 618\nm: 1369\nk_avg: 4.4304\nedge_length_total: 144030.3630\nedge_length_avg: 105.2084\nstreets_per_node_avg: 3.1586\nstreets_per_node_counts: dict\nstreets_per_node_proportions: dict\nintersection_count: 573\nstreet_length_total: 103022.5250\nstreet_segment_count: 945\nstreet_length_avg: 109.0185\ncircuity_avg: 1.0197\nself_loop_proportion: 0.0011\n\n=== Calculating Centrality Metrics ===\nNote: for MultiDiGraph we aggregate to a simple undirected graph for centrality calculations.\nCalculating betweenness centrality (this can be slow for bigger graphs)...\nCalculating closeness centrality...\nCentrality calculations complete!\n\nNumber of dead ends: 4\nNumber of intersections: 551\nAverage node degree: 4.43\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCleaning geometries and attributes for export...\nGeometry + attribute cleaning complete!\n\n=== Files saved successfully ===\n- current_network_nodes.geojson\n- current_network_edges.geojson\n\n\n\n\nCode\n# ============================================================================\n# 9. (OPTIONAL) COMPARE WITH MISSING STREETS - Uncomment and edit path\n# ============================================================================\n\nprint(\"\\n=== Comparing with Historical Network ===\")\nmissing_streets = gpd.read_file(\"../data/streets/cincinnati_kenyon_barr_streets.geojson\")\n\nif missing_streets.crs != edges_gdf.crs:\n    missing_streets = missing_streets.to_crs(edges_gdf.crs)\n\n# Project to UTM zone 17N (meters)\nedges_m = edges_gdf.to_crs(26917)\nmissing_m = missing_streets.to_crs(26917)\n\nmissing_length = missing_m.geometry.length.sum()\ncurrent_length = edges_m.geometry.length.sum()\n\nprint(f\"Current street network: {current_length:.0f} meters\")\nprint(f\"Historical streets: {missing_length:.0f} meters\")\nprint(f\"Historical network was {(missing_length/current_length)*100:.1f}% longer\")\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\nedges_gdf.plot(ax=ax1, color='blue', linewidth=1, alpha=0.7)\nax1.set_title('Current Street Network', fontsize=16)\nax1.axis('off')\n\nedges_gdf.plot(ax=ax2, color='blue', linewidth=1, alpha=0.7, label='Current')\nmissing_streets.plot(ax=ax2, color='red', linewidth=2, alpha=0.7, label='Historical')\nax2.set_title('Current vs Historical Streets', fontsize=16)\nax2.legend()\nax2.axis('off')\n\nplt.tight_layout()\nplt.show()\n\n\n\n=== Comparing with Historical Network ===\nCurrent street network: 144225 meters\nHistorical streets: 24272 meters\nHistorical network was 16.8% longer"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "This project examines the lasting impact of mid-20th century urban renewal policies on Cincinnati’s street networks and neighborhoods. Between the 1950s and 1970s, large-scale infrastructure projects—including interstate highway construction and urban redevelopment—fundamentally reshaped the urban fabric of American cities. This website documents what was lost and explores the ongoing effects on connectivity and community."
  },
  {
    "objectID": "index.html#navigate-the-project-website",
    "href": "index.html#navigate-the-project-website",
    "title": "Welcome",
    "section": "Navigate The Project Website",
    "text": "Navigate The Project Website\n\nTechnical Report\nThe project report detailing methodology, results, and conclusions.\n\n\nInteractive Component\nThis is where the polished result of most of the Python code exists.\n\n\nExploratory Analysis\nThe raw processing code is organized into these sub-pages. For example, “Historical Aerial Imagery” contains the Python code that was used process aerial imagery, and into an HTML Folium component.\n\nHistorical Aerial Imagery\n\nLibraries Used: Rasterio, Folium, PIL, Pyproj\n\nHistorical Census Data\n\nLibraries Used: Pygris, Cenpy, Matplotlib, Geopandas, Pandas\n\nStreet Network Analysis\n\nLibraries Used:"
  },
  {
    "objectID": "index.html#about-this-project",
    "href": "index.html#about-this-project",
    "title": "Welcome",
    "section": "About This Project",
    "text": "About This Project\nThis work is part of MUSA 5500 at the University of Pennsylvania Weitzman School of Design. The project focuses on Cincinnati, Ohio, as a case study to work towards a more replicatable workflow.\n\nData Sources\n\nHistorical Imagery: Ohio Department of Transportation (ODOT) aerial photography archive (1946-present).\nSanborn Maps: Fire insurance maps showing detailed street networks from Cincinnati Public Library and the Ohio Web Library.\nStreet Networks: OpenStreetMap data via OSMnx.\nCensus Data: Historical and contemporary demographic data from"
  }
]